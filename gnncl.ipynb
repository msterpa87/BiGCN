{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "from tensorflow.keras.activations import relu\n",
    "from spektral.layers import GraphSageConv\n",
    "from contextlib import suppress\n",
    "import copy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(tf.keras.Model):\n",
    "    def __init__(self, hidden_channels, out_channels, add_linear=True):\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = GraphSageConv(hidden_channels)\n",
    "        self.bn1 = BatchNormalization()\n",
    "        self.conv2 = GraphSageConv(hidden_channels)\n",
    "        self.bn2 = BatchNormalization()\n",
    "        self.conv3 = GraphSageConv(out_channels)\n",
    "        self.bn3 = BatchNormalization()\n",
    "        \n",
    "        if add_linear:\n",
    "            self.lin = Dense(out_channels)\n",
    "        else:\n",
    "            self.lin = None\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x, adj = inputs\n",
    "        \n",
    "        x1 = self.bn1(relu(self.conv1(inputs)))\n",
    "        x2 = self.bn2(relu(self.conv2([x1, adj])))\n",
    "        x3 = self.bn3(relu(self.conv3([x2, adj])))\n",
    "\n",
    "        x = tf.concat([x1, x2, x3], axis=-1)\n",
    "\n",
    "        if self.lin is not None:\n",
    "            x = relu(self.lin(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf.zeros((10,0)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_diff_pool(x, adj, s):\n",
    "    # https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/dense/diff_pool.html#dense_diff_pool\n",
    "    # add batch dimension if necessary\n",
    "    with suppress(TypeError):\n",
    "        adj = tf.sparse.to_dense(adj)\n",
    "        s = tf.sparse.to_dense(adj)\n",
    "\n",
    "    x = tf.expand_dims(x, axis=0) if len(x.shape) == 2 else x\n",
    "    adj = tf.expand_dims(adj, axis=0) if len(adj.shape) == 2 else adj\n",
    "    s = tf.expand_dims(s, axis=0) if len(s.shape) == 2 else s\n",
    "\n",
    "    batch_size, num_nodes, _ = x.shape  # used when maks is implemented\n",
    "\n",
    "    # s = tf.nn.softmax(s, axis=-1)\n",
    "    s = tf.nn.softmax(s, axis=-1)    # check if this works as tf.nn.softmax(x, axis=-1)\n",
    "    st = tf.transpose(s, (0, 2, 1))\n",
    "\n",
    "    out = tf.matmul(st, x)\n",
    "    out_adj = tf.matmul(tf.matmul(st, adj), s)\n",
    "\n",
    "    link_loss = adj - tf.matmul(s, st)\n",
    "    link_loss = tf.norm(link_loss, ord=2)\n",
    "    link_loss = link_loss / tf.size(adj, out_type=tf.dtypes.float32)\n",
    "\n",
    "    ent_loss = tf.reduce_mean(tf.reduce_sum(-s * tf.math.log(s + 1e-15), axis=-1))\n",
    "\n",
    "    return out, out_adj, link_loss, ent_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(tf.keras.Model):\n",
    "    def __init__(self, in_channels=3, num_classes=6, max_nodes=200):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        num_nodes = tf.math.ceil(0.25 * max_nodes)\n",
    "        self.gnn1_pool = GNN(64, num_nodes)\n",
    "        self.gnn1_embed = GNN(64, 64, add_linear=False)\n",
    "\n",
    "        num_nodes = tf.math.ceil(0.25 * max_nodes)\n",
    "        self.gnn2_pool = GNN(63, num_nodes)\n",
    "        self.gnn1_embed = GNN(64, 64, add_linear=False)\n",
    "\n",
    "        self.gnn3_embed = GNN(64, 64, add_linear=False)\n",
    "\n",
    "        self.lin1 = Dense(64)\n",
    "        self.lin2 = Dense(num_classes)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x, adj = inputs\n",
    "        s = self.gnn1_pool([x, adj])\n",
    "        x = self.gnn1_embed([x, adj])\n",
    "\n",
    "        x, adj, l1, e1 = dense_diff_pool(x, adj, s)\n",
    "\n",
    "        s = self.gnn2_pool([x, adj])\n",
    "        x = self.gnn2_embed([x, adj])\n",
    "\n",
    "        x, adj, l2, e2 = dense_diff_pool(x, adj, s)\n",
    "\n",
    "        x = self.gnn3_embed([x, adj])\n",
    "\n",
    "        x = tf.reduce_mean(x, axis=1)\n",
    "        x = relu(self.lin1(x))\n",
    "        x = self.lin2(x)\n",
    "\n",
    "        return tf.nn.log_softmax(x, axis=-1), l1 + l2, e1 + e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 8), dtype=float32, numpy=\n",
       "array([[0.07391645, 0.        , 0.22801805, 0.        , 0.        ,\n",
       "        0.19222161, 0.10885294, 0.01520273],\n",
       "       [0.        , 0.12564272, 0.17030147, 0.0176785 , 0.        ,\n",
       "        0.        , 0.11459391, 0.        ],\n",
       "       [0.        , 0.21832334, 0.19624911, 0.        , 0.        ,\n",
       "        0.04222625, 0.08397265, 0.        ],\n",
       "       [0.        , 0.15233031, 0.15863347, 0.0828501 , 0.        ,\n",
       "        0.1525804 , 0.18321669, 0.06215439],\n",
       "       [0.        , 0.02776095, 0.26309374, 0.        , 0.        ,\n",
       "        0.15623054, 0.        , 0.01747207],\n",
       "       [0.01652861, 0.25542983, 0.17841187, 0.07956162, 0.        ,\n",
       "        0.        , 0.27369484, 0.        ],\n",
       "       [0.02258293, 0.        , 0.05399239, 0.11350705, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.3260104 , 0.09149566, 0.13620564, 0.        ,\n",
       "        0.09080829, 0.19152896, 0.        ],\n",
       "       [0.05179439, 0.        , 0.19057748, 0.02402694, 0.00725532,\n",
       "        0.21728821, 0.10770077, 0.06973204],\n",
       "       [0.        , 0.20962329, 0.23052287, 0.12430925, 0.        ,\n",
       "        0.15395874, 0.2391193 , 0.02979611]], dtype=float32)>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_nodes = 10\n",
    "num_features = 5\n",
    "\n",
    "x = tf.Variable(tf.random.normal((num_nodes, num_features)))\n",
    "adj = tf.sparse.from_dense(tf.round(tf.random.uniform((num_nodes, num_nodes))))\n",
    "\n",
    "#bn(relu(gnn([x, adj]))).shape\n",
    "gnn = GNN(64, 8)\n",
    "gnn([x, adj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 64])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4a0cdf5044e235b24d1fc042fb09c724f9ff16da5a82a5cb2270a9975034c9c0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
