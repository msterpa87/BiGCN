{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3129b196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "from os import mkdir, listdir\n",
    "from contextlib import suppress\n",
    "from utils import get_twitter_api\n",
    "from tweepy.errors import NotFound, Forbidden\n",
    "import json\n",
    "\n",
    "MAX_TWEETS = 2000\n",
    "MAX_REQUESTS = 100\n",
    "\n",
    "api = get_twitter_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1157aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tweets(news_id, tweet_ids, path):\n",
    "    n = len(tweet_ids)\n",
    "    idx_list = list(range(0, n, MAX_REQUESTS)) + [n]\n",
    "\n",
    "    for idx, i in enumerate(idx_list[:-1]):\n",
    "        chunk = tweet_ids[i:idx_list[idx+1]]\n",
    "\n",
    "        status_list = api.lookup_statuses(id=chunk)\n",
    "        retweets_list = []\n",
    "        \n",
    "        # get retweets\n",
    "        for tweet in status_list:\n",
    "            if tweet.retweet_count:\n",
    "                with suppress(NotFound, Forbidden):\n",
    "                    retweets = api.get_retweets(tweet.id)\n",
    "                    # add field to retrieve ID of original tweet\n",
    "                    for x in retweets:\n",
    "                        x._json['retweed_from'] = tweet.id\n",
    "                    \n",
    "                    retweets_list.extend(retweets)\n",
    "\n",
    "        if len(retweets_list):\n",
    "            print(f\"Found a total of {len(retweets_list)} retweets.\")\n",
    "\n",
    "            json_path = f\"{path}/retweets/{news_id}\"\n",
    "            mkdir(json_path)\n",
    "\n",
    "            for retweet in retweets_list:\n",
    "                with open(f\"{json_path}/{retweet.id_str}.json\", \"w\") as f:\n",
    "                    json.dump(retweet._json, f)\n",
    "        \n",
    "        continue\n",
    "\n",
    "        json_path = f\"{path}/tweets/{news_id}\"\n",
    "        mkdir(json_path)\n",
    "\n",
    "        for tweet in status_list:\n",
    "            with open(f\"{json_path}/{tweet.id_str}.json\", \"w\") as f:\n",
    "                json.dump(tweet._json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e593be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 of 409\n",
      "politifact14984: 1174 tweets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a total of 100 retweets.\n",
      "Found a total of 78 retweets.\n",
      "politifact12944: 51 tweets\n",
      "Found a total of 26 retweets.\n",
      "politifact779: 8 tweets\n",
      "Found a total of 0 retweets.\n",
      "politifact14064: 30 tweets\n",
      "Found a total of 26 retweets.\n",
      "politifact14474: 96 tweets\n",
      "Found a total of 57 retweets.\n",
      "politifact1313: 1882 tweets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 871\n"
     ]
    }
   ],
   "source": [
    "for dataset in [\"politifact\"]:\n",
    "    for news_type in [\"real\", \"fake\"]:\n",
    "        df = pd.read_csv(f\"dataset/FakeNewsNet/{dataset}_{news_type}.csv\")\n",
    "        df = df[~df['tweet_ids'].isnull()]\n",
    "        n = len(df)\n",
    "        \n",
    "        for i, (news_id, url, title, tweet_ids) in df.iterrows():\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Processed {i} of {n}\")\n",
    "            \n",
    "            # convert tweet ids string to ints\n",
    "            tweet_ids = list(map(int, tweet_ids.split('\\t')))[:MAX_TWEETS]\n",
    "\n",
    "            with suppress(FileExistsError):\n",
    "                path = f\"./dataset/FakeNewsNet/{dataset}/{news_type}\"\n",
    "                print(f\"{news_id}: {len(tweet_ids)} tweets\")\n",
    "                save_tweets(news_id, tweet_ids, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12abb966",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
