{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5117a36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_api_keys():\n",
    "    with open(\"./twitter_api.txt\") as f:\n",
    "        data = list(map(str.strip, f.readlines()))\n",
    "    return dict(list(map(lambda s: s.replace(\"\\\"\",\"\").split(\" = \"), data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3129b196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "from os import mkdir\n",
    "from contextlib import suppress\n",
    "\n",
    "MAX_TWEETS = 2000\n",
    "MAX_REQUESTS = 100\n",
    "\n",
    "auth_keys = load_api_keys()\n",
    "\n",
    "auth = tweepy.OAuthHandler(auth_keys[\"consumer_key\"], auth_keys[\"consumer_secret\"])\n",
    "  \n",
    "# set access to user's access key and access secret \n",
    "auth.set_access_token(auth_keys[\"access_token\"], auth_keys[\"access_token_secret\"])\n",
    "  \n",
    "# calling the api \n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1157aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tweets(tweet_ids, json_path):\n",
    "    n = len(tweet_ids)\n",
    "    idx_list = list(range(0, n, MAX_REQUESTS)) + [n]\n",
    "\n",
    "    for idx, i in enumerate(idx_list[:-1]):\n",
    "        chunk = tweet_ids[i:idx_list[idx+1]]\n",
    "        status_list = api.lookup_statuses(id=chunk)\n",
    "\n",
    "        for i,tweet in enumerate(status_list):\n",
    "            with open(f\"{json_path}/{tweet.id_str}.json\", \"w\") as f:\n",
    "                json.dump(tweet._json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3e593be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "politifact10185: 126 tweets\n",
      "politifact1500: 16 tweets\n",
      "politifact98: 151 tweets\n",
      "politifact12751: 2000 tweets\n",
      "politifact8172: 15 tweets\n",
      "politifact179: 1016 tweets\n",
      "politifact8119: 444 tweets\n",
      "politifact8621: 1 tweets\n",
      "politifact11931: 244 tweets\n",
      "politifact975: 5 tweets\n",
      "politifact181: 1788 tweets\n",
      "politifact581: 12 tweets\n",
      "politifact621: 2 tweets\n",
      "politifact93: 1020 tweets\n",
      "politifact466: 107 tweets\n",
      "politifact8537: 800 tweets\n",
      "politifact463: 1 tweets\n",
      "politifact1361: 154 tweets\n",
      "politifact6907: 3 tweets\n",
      "politifact679: 4 tweets\n",
      "politifact12104: 2000 tweets\n",
      "politifact7182: 3 tweets\n",
      "politifact8470: 82 tweets\n",
      "politifact15133: 431 tweets\n",
      "politifact1118: 5 tweets\n",
      "politifact304: 1496 tweets\n",
      "politifact2281: 54 tweets\n",
      "politifact1560: 4 tweets\n",
      "politifact810: 541 tweets\n",
      "politifact263: 88 tweets\n",
      "politifact5321: 8 tweets\n",
      "politifact3527: 3 tweets\n",
      "politifact651: 17 tweets\n",
      "politifact943: 50 tweets\n",
      "politifact11552: 4 tweets\n",
      "politifact574: 1 tweets\n",
      "politifact2836: 3 tweets\n",
      "politifact8557: 24 tweets\n",
      "politifact12556: 968 tweets\n",
      "politifact426: 2 tweets\n",
      "politifact997: 69 tweets\n",
      "politifact421: 9 tweets\n",
      "politifact368: 1527 tweets\n",
      "politifact201: 3 tweets\n",
      "politifact7665: 13 tweets\n",
      "politifact10903: 75 tweets\n",
      "politifact1424: 66 tweets\n",
      "politifact340: 964 tweets\n",
      "politifact379: 30 tweets\n",
      "politifact186: 11 tweets\n",
      "politifact751: 1307 tweets\n",
      "politifact288: 89 tweets\n",
      "politifact99: 2000 tweets\n",
      "politifact700: 307 tweets\n",
      "politifact12120: 1025 tweets\n",
      "politifact13052: 48 tweets\n",
      "politifact648: 1225 tweets\n",
      "politifact3428: 13 tweets\n",
      "politifact2724: 1 tweets\n",
      "politifact13395: 66 tweets\n",
      "politifact12486: 2000 tweets\n",
      "politifact1028: 23 tweets\n",
      "politifact13244: 22 tweets\n",
      "politifact14174: 29 tweets\n",
      "politifact13855: 638 tweets\n",
      "politifact6537: 1472 tweets\n",
      "politifact6519: 18 tweets\n",
      "politifact74: 36 tweets\n",
      "politifact13305: 48 tweets\n",
      "politifact13229: 486 tweets\n",
      "politifact2131: 9 tweets\n",
      "politifact8005: 2000 tweets\n",
      "politifact11314: 14 tweets\n",
      "politifact323: 716 tweets\n",
      "politifact938: 10 tweets\n",
      "politifact674: 1416 tweets\n",
      "politifact649: 626 tweets\n",
      "politifact939: 5 tweets\n",
      "politifact1924: 11 tweets\n",
      "politifact1185: 20 tweets\n",
      "politifact1053: 1644 tweets\n",
      "politifact208: 2 tweets\n",
      "politifact12587: 457 tweets\n",
      "politifact8805: 9 tweets\n",
      "politifact10348: 2000 tweets\n",
      "politifact13352: 1024 tweets\n",
      "politifact7: 3 tweets\n",
      "politifact1014: 3 tweets\n",
      "politifact13548: 40 tweets\n",
      "politifact14114: 1040 tweets\n",
      "politifact10371: 2000 tweets\n",
      "politifact303: 2000 tweets\n",
      "politifact2208: 5 tweets\n",
      "politifact13900: 2000 tweets\n"
     ]
    }
   ],
   "source": [
    "for dataset in [\"politifact\", \"gossipcop\"]:\n",
    "    for news_type in [\"real\", \"fake\"]:\n",
    "        df = pd.read_csv(f\"dataset/FakeNewsNet/{dataset}_{news_type}.csv\")\n",
    "        df = df[~df['tweet_ids'].isnull()]\n",
    "        \n",
    "        for i, (news_id, url, title, tweet_ids) in df.iterrows():\n",
    "            # convert tweet ids string to ints\n",
    "            tweet_ids = list(map(int, tweet_ids.split('\\t')))[:MAX_TWEETS]\n",
    "\n",
    "            with suppress(FileExistsError):\n",
    "                json_path = f\"./dataset/FakeNewsNet/{dataset}/{news_type}/{news_id}\"\n",
    "                mkdir(json_path)\n",
    "                print(f\"{news_id}: {len(tweet_ids)} tweets\")\n",
    "                save_tweets(tweet_ids, json_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
